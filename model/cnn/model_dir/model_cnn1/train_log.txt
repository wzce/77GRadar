D:\Anaconda\python.exe D:/home/zeewei/projects/77GRadar/model/cnn/cnn1.py
start fetching train data--->
read from processed numpy file--->
start fetching test data--->
read from processed numpy file--->
D:\Anaconda\lib\site-packages\torch\nn\modules\container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
0  train_mean_loss:  0.07011151216069206  test_loss:  0.7023625
1  train_mean_loss:  0.07006013736532156  test_loss:  0.7010635
2  train_mean_loss:  0.07002940177463003  test_loss:  0.6999443
3  train_mean_loss:  0.07000380311355853  test_loss:  0.6990969
4  train_mean_loss:  0.06997486250208754  test_loss:  0.6981563
5  train_mean_loss:  0.06997225260034663  test_loss:  0.6981799
6  train_mean_loss:  0.06996725174110899  test_loss:  0.69770366
7  train_mean_loss:  0.06996752456358904  test_loss:  0.6988993
8  train_mean_loss:  0.06995729006204812  test_loss:  0.6977209
9  train_mean_loss:  0.06996250082143972  test_loss:  0.69742763
10  train_mean_loss:  0.06995130471496058  test_loss:  0.6977762
11  train_mean_loss:  0.06993875417643906  test_loss:  0.6973653
12  train_mean_loss:  0.06995593715250333  test_loss:  0.69788575
13  train_mean_loss:  0.06993645595495272  test_loss:  0.6973221
14  train_mean_loss:  0.06993546115047733  test_loss:  0.69736755
15  train_mean_loss:  0.06993302908554543  test_loss:  0.6973616
16  train_mean_loss:  0.06992710004814517  test_loss:  0.69746095
17  train_mean_loss:  0.06992820483602916  test_loss:  0.69747126
18  train_mean_loss:  0.06992498145865157  test_loss:  0.69759125
19  train_mean_loss:  0.06992189358356024  test_loss:  0.6972915
20  train_mean_loss:  0.06992391571033288  test_loss:  0.69737715
21  train_mean_loss:  0.06991392064994408  test_loss:  0.6977848
22  train_mean_loss:  0.0699164711515548  test_loss:  0.69750714
23  train_mean_loss:  0.06991633239975878  test_loss:  0.6971749
24  train_mean_loss:  0.06990725470098247  test_loss:  0.69697845
25  train_mean_loss:  0.06993830263092006  test_loss:  0.6970191
26  train_mean_loss:  0.06990935806550008  test_loss:  0.6970517
27  train_mean_loss:  0.06990780666317142  test_loss:  0.69701856
28  train_mean_loss:  0.06992185808891474  test_loss:  0.6971027
29  train_mean_loss:  0.06991655238929978  test_loss:  0.6973573
30  train_mean_loss:  0.0699070531177557  test_loss:  0.6970454
31  train_mean_loss:  0.0699185051401744  test_loss:  0.696824
32  train_mean_loss:  0.06990571381979392  test_loss:  0.69703907
33  train_mean_loss:  0.06990738213630382  test_loss:  0.69667435
34  train_mean_loss:  0.06990444848794679  test_loss:  0.6967877
35  train_mean_loss:  0.06990832258534259  test_loss:  0.69660974
36  train_mean_loss:  0.0699100739347812  test_loss:  0.69748855
37  train_mean_loss:  0.06990305135780012  test_loss:  0.69709647
38  train_mean_loss:  0.06990413130852179  test_loss:  0.6970392
39  train_mean_loss:  0.06990855759534498  test_loss:  0.696737
40  train_mean_loss:  0.06991274525907445  test_loss:  0.6970961
41  train_mean_loss:  0.06990790910226355  test_loss:  0.697523
42  train_mean_loss:  0.06990256690815393  test_loss:  0.6971834
43  train_mean_loss:  0.0699133013342793  test_loss:  0.69730264
44  train_mean_loss:  0.06990625871486715  test_loss:  0.6969354
45  train_mean_loss:  0.0699113119752908  test_loss:  0.697038
46  train_mean_loss:  0.06991358944990687  test_loss:  0.69710535
47  train_mean_loss:  0.06991558683041257  test_loss:  0.69661516
48  train_mean_loss:  0.06990691545670423  test_loss:  0.6969076
49  train_mean_loss:  0.06990958859890506  test_loss:  0.6966855
50  train_mean_loss:  0.0699055395279047  test_loss:  0.6968268
51  train_mean_loss:  0.0699020715737861  test_loss:  0.69688386
52  train_mean_loss:  0.06990484656425909  test_loss:  0.6967148
53  train_mean_loss:  0.06991062162488733  test_loss:  0.6974114
54  train_mean_loss:  0.06990752238787361  test_loss:  0.6967282
55  train_mean_loss:  0.06990148822996756  test_loss:  0.6970139
56  train_mean_loss:  0.06990461380391734  test_loss:  0.69727004
57  train_mean_loss:  0.06989893670578382  test_loss:  0.69659907
58  train_mean_loss:  0.06990138047349576  test_loss:  0.69711167
59  train_mean_loss:  0.06990882414604388  test_loss:  0.69672865
60  train_mean_loss:  0.06990533226371674  test_loss:  0.6972416
61  train_mean_loss:  0.06991046792080145  test_loss:  0.69654715
62  train_mean_loss:  0.0699044704846285  test_loss:  0.69683
63  train_mean_loss:  0.06990642521247761  test_loss:  0.6967887
64  train_mean_loss:  0.06990309046553693  test_loss:  0.6969103
65  train_mean_loss:  0.06990243117862924  test_loss:  0.6967553
66  train_mean_loss:  0.06990406293247294  test_loss:  0.6966656
67  train_mean_loss:  0.06990040248466547  test_loss:  0.6968805
68  train_mean_loss:  0.06990283686742954  test_loss:  0.69686455
69  train_mean_loss:  0.06990527361347346  test_loss:  0.6967254
70  train_mean_loss:  0.06990633338542099  test_loss:  0.69669276
71  train_mean_loss:  0.06990329125342913  test_loss:  0.69678396
72  train_mean_loss:  0.06990868582600089  test_loss:  0.69688433
73  train_mean_loss:  0.06990654246751653  test_loss:  0.6967984
74  train_mean_loss:  0.06990470872141685  test_loss:  0.6968664
75  train_mean_loss:  0.06989891343656679  test_loss:  0.69673896
76  train_mean_loss:  0.06990128935087832  test_loss:  0.6967637
77  train_mean_loss:  0.06989471179767279  test_loss:  0.69675225
78  train_mean_loss:  0.06990843484113564  test_loss:  0.6967329
79  train_mean_loss:  0.06989762138147823  test_loss:  0.6969158
80  train_mean_loss:  0.06989105584918658  test_loss:  0.6969721
81  train_mean_loss:  0.06991078305508043  test_loss:  0.69688004
82  train_mean_loss:  0.0699071907788072  test_loss:  0.69702953
83  train_mean_loss:  0.06988815205996154  test_loss:  0.6968391
84  train_mean_loss:  0.06990309103363304  test_loss:  0.6971213
85  train_mean_loss:  0.06989453266560464  test_loss:  0.6967869
86  train_mean_loss:  0.06989597908377057  test_loss:  0.6966727
87  train_mean_loss:  0.06989441625134798  test_loss:  0.6968221
88  train_mean_loss:  0.06989047448234252  test_loss:  0.6968598
89  train_mean_loss:  0.06991199187272566  test_loss:  0.69679075
90  train_mean_loss:  0.06989458336250226  test_loss:  0.69681185
91  train_mean_loss:  0.0698917427228418  test_loss:  0.69663733
92  train_mean_loss:  0.06989953502461604  test_loss:  0.69672734
93  train_mean_loss:  0.06990143221569024  test_loss:  0.696891
94  train_mean_loss:  0.06991228591927671  test_loss:  0.69672513
95  train_mean_loss:  0.06990488033189239  test_loss:  0.6968537
96  train_mean_loss:  0.0698925948897437  test_loss:  0.69668573
97  train_mean_loss:  0.0698983523621161  test_loss:  0.6965355
98  train_mean_loss:  0.06989337824884372  test_loss:  0.6968964
99  train_mean_loss:  0.06989491231287885  test_loss:  0.6968444
100  train_mean_loss:  0.06990066012761723  test_loss:  0.696806
101  train_mean_loss:  0.06989313155878513  test_loss:  0.6968897
102  train_mean_loss:  0.06988875849120635  test_loss:  0.6967847
103  train_mean_loss:  0.06989434564836235  test_loss:  0.6967438
104  train_mean_loss:  0.06989330553254053  test_loss:  0.6967983
105  train_mean_loss:  0.06989577497819703  test_loss:  0.6967762
106  train_mean_loss:  0.06988678985636425  test_loss:  0.6967884
107  train_mean_loss:  0.069903394169722  test_loss:  0.69664645
108  train_mean_loss:  0.06989065509146059  test_loss:  0.6967907
109  train_mean_loss:  0.06991148513098777  test_loss:  0.69671005
110  train_mean_loss:  0.06988885577198571  test_loss:  0.6967408
111  train_mean_loss:  0.06989871723889123  test_loss:  0.69657236
112  train_mean_loss:  0.06988790350654768  test_loss:  0.6965527
113  train_mean_loss:  0.06989521803948609  test_loss:  0.69669104
114  train_mean_loss:  0.06989882063238484  test_loss:  0.69685006
115  train_mean_loss:  0.0699095133602551  test_loss:  0.69691634
116  train_mean_loss:  0.06990090109126694  test_loss:  0.69673735
117  train_mean_loss:  0.06989648582550846  test_loss:  0.6966979
118  train_mean_loss:  0.06988944375146858  test_loss:  0.6967133
119  train_mean_loss:  0.06989278492925734  test_loss:  0.69657683
120  train_mean_loss:  0.06988798460794958  test_loss:  0.6966676
121  train_mean_loss:  0.0698908746265247  test_loss:  0.6968518
122  train_mean_loss:  0.06990074927326018  test_loss:  0.69674546
123  train_mean_loss:  0.06988393665041762  test_loss:  0.69676334
124  train_mean_loss:  0.06989048073139983  test_loss:  0.6968172
125  train_mean_loss:  0.06989059291902136  test_loss:  0.6968419
126  train_mean_loss:  0.06989147903534733  test_loss:  0.69680053
127  train_mean_loss:  0.0699008688234074  test_loss:  0.6967833
128  train_mean_loss:  0.06989519174799771  test_loss:  0.69681287
129  train_mean_loss:  0.0699059369906732  test_loss:  0.6969433
130  train_mean_loss:  0.06990154133559273  test_loss:  0.696842
131  train_mean_loss:  0.06989499293708001  test_loss:  0.6968253
132  train_mean_loss:  0.06989811551148228  test_loss:  0.69675994
133  train_mean_loss:  0.06989423266540626  test_loss:  0.69678295
134  train_mean_loss:  0.06989264154179697  test_loss:  0.69688797
135  train_mean_loss:  0.06990003292677832  test_loss:  0.6968415
136  train_mean_loss:  0.06989474245213935  test_loss:  0.69685954
137  train_mean_loss:  0.06990415205539205  test_loss:  0.6968689
138  train_mean_loss:  0.06989198591342828  test_loss:  0.6968009
139  train_mean_loss:  0.06989182064290543  test_loss:  0.6967772
140  train_mean_loss:  0.06989083947273687  test_loss:  0.6967076
141  train_mean_loss:  0.06990018626728269  test_loss:  0.6967006
142  train_mean_loss:  0.06990038041981222  test_loss:  0.69677496
143  train_mean_loss:  0.06989344923813472  test_loss:  0.69678247
144  train_mean_loss:  0.06988430316330957  test_loss:  0.6966473
145  train_mean_loss:  0.06989544470983745  test_loss:  0.6965603
146  train_mean_loss:  0.0699003499925841  test_loss:  0.6967058
147  train_mean_loss:  0.06991676665243192  test_loss:  0.69669265
148  train_mean_loss:  0.06989772695646093  test_loss:  0.69655514
149  train_mean_loss:  0.06989717135845683  test_loss:  0.6964654
150  train_mean_loss:  0.06989134051078974  test_loss:  0.6965554
151  train_mean_loss:  0.06988781963283672  test_loss:  0.6965942
152  train_mean_loss:  0.06988948422263608  test_loss:  0.6967194
153  train_mean_loss:  0.0698984380310108  test_loss:  0.69645745
154  train_mean_loss:  0.0698971531112095  test_loss:  0.6966403
155  train_mean_loss:  0.06988821416422923  test_loss:  0.6966353
156  train_mean_loss:  0.06988857340549086  test_loss:  0.69661623
157  train_mean_loss:  0.06989403092311258  test_loss:  0.69662756
158  train_mean_loss:  0.06989585985175717  test_loss:  0.69645816
159  train_mean_loss:  0.06989109981982616  test_loss:  0.69657904
160  train_mean_loss:  0.06989897274580158  test_loss:  0.69648266
161  train_mean_loss:  0.06988870845330021  test_loss:  0.69645005
162  train_mean_loss:  0.06989002298227122  test_loss:  0.69674313
163  train_mean_loss:  0.06989326417514308  test_loss:  0.69659245
164  train_mean_loss:  0.06988898400264162  test_loss:  0.69649017
165  train_mean_loss:  0.06989721882856852  test_loss:  0.69647866
166  train_mean_loss:  0.06990157526229294  test_loss:  0.69674706
167  train_mean_loss:  0.06989059157831451  test_loss:  0.6965379
168  train_mean_loss:  0.06988952669350192  test_loss:  0.6964365
169  train_mean_loss:  0.06988790062061939  test_loss:  0.6966245
170  train_mean_loss:  0.06989897440464225  test_loss:  0.696659
171  train_mean_loss:  0.06988836370985152  test_loss:  0.69661486
172  train_mean_loss:  0.06989209357900471  test_loss:  0.69659543
173  train_mean_loss:  0.069891810167213  test_loss:  0.69673276
174  train_mean_loss:  0.06990430528227719  test_loss:  0.69659144
175  train_mean_loss:  0.06990197774703112  test_loss:  0.6965887
176  train_mean_loss:  0.06989095084229999  test_loss:  0.69673
177  train_mean_loss:  0.06989801514026003  test_loss:  0.6968275
178  train_mean_loss:  0.06988616785928578  test_loss:  0.6965566
179  train_mean_loss:  0.06988776500471394  test_loss:  0.6966065
180  train_mean_loss:  0.06989396693276577  test_loss:  0.69660705
181  train_mean_loss:  0.06988776770885147  test_loss:  0.6966019
182  train_mean_loss:  0.0698986764950376  test_loss:  0.69679075
183  train_mean_loss:  0.0698944815596778  test_loss:  0.6967948
184  train_mean_loss:  0.06988658338751086  test_loss:  0.69675845
185  train_mean_loss:  0.06989561879721208  test_loss:  0.696734
186  train_mean_loss:  0.06990290240299779  test_loss:  0.69676864
187  train_mean_loss:  0.0698994158153265  test_loss:  0.6967626
188  train_mean_loss:  0.06990277492222875  test_loss:  0.69650155
189  train_mean_loss:  0.06989289416277904  test_loss:  0.6964832
190  train_mean_loss:  0.06990578190043278  test_loss:  0.6965157
191  train_mean_loss:  0.06989181977939933  test_loss:  0.6964419
192  train_mean_loss:  0.06989982484453196  test_loss:  0.6965092
193  train_mean_loss:  0.06988704345447164  test_loss:  0.6965119
194  train_mean_loss:  0.06988874192552352  test_loss:  0.6964869
195  train_mean_loss:  0.06989124541149946  test_loss:  0.69655013
196  train_mean_loss:  0.06988776461840858  test_loss:  0.6965269
197  train_mean_loss:  0.06989543811992248  test_loss:  0.69656676
198  train_mean_loss:  0.06988823032088286  test_loss:  0.6965892
199  train_mean_loss:  0.06989499466409221  test_loss:  0.6967013
200  train_mean_loss:  0.069900655037476  test_loss:  0.69651246
201  train_mean_loss:  0.06988807411717406  test_loss:  0.69656616
202  train_mean_loss:  0.06988825413547214  test_loss:  0.69644064
203  train_mean_loss:  0.06988680251354577  test_loss:  0.69657737
204  train_mean_loss:  0.06989013923746096  test_loss:  0.69658476
205  train_mean_loss:  0.0698962093899371  test_loss:  0.6966249
206  train_mean_loss:  0.06988927284543223  test_loss:  0.6965555
207  train_mean_loss:  0.0698902450396821  test_loss:  0.6966875
208  train_mean_loss:  0.06989114867609238  test_loss:  0.6966616
209  train_mean_loss:  0.0699000287455909  test_loss:  0.6965702
210  train_mean_loss:  0.06988437481159206  test_loss:  0.69670045
211  train_mean_loss:  0.06990109028999832  test_loss:  0.6964617
212  train_mean_loss:  0.06989329926075938  test_loss:  0.69670045
213  train_mean_loss:  0.0698981174430091  test_loss:  0.69673073
214  train_mean_loss:  0.06990237257383364  test_loss:  0.6967289
215  train_mean_loss:  0.06989436255490285  test_loss:  0.69667125
216  train_mean_loss:  0.06989323272534195  test_loss:  0.6967304
217  train_mean_loss:  0.06989134889588845  test_loss:  0.69679266
218  train_mean_loss:  0.06990013302531445  test_loss:  0.6967834
219  train_mean_loss:  0.06988721713281705  test_loss:  0.6966172
220  train_mean_loss:  0.06988881107418309  test_loss:  0.69642234
221  train_mean_loss:  0.06989101219668081  test_loss:  0.69634664
222  train_mean_loss:  0.06988896693703422  test_loss:  0.6964666
223  train_mean_loss:  0.06988873188158413  test_loss:  0.69650507
224  train_mean_loss:  0.06988654893816222  test_loss:  0.6966002
225  train_mean_loss:  0.06989500204934176  test_loss:  0.6966988
226  train_mean_loss:  0.06989449128548335  test_loss:  0.69665277
227  train_mean_loss:  0.06989004122951856  test_loss:  0.69636923
228  train_mean_loss:  0.06989077680037306  test_loss:  0.6966171
229  train_mean_loss:  0.06988900904431854  test_loss:  0.69659775
230  train_mean_loss:  0.06989998107096461  test_loss:  0.6968256
231  train_mean_loss:  0.06990194127526031  test_loss:  0.6968244
232  train_mean_loss:  0.06989587537214313  test_loss:  0.6968032
233  train_mean_loss:  0.06989243952681716  test_loss:  0.69687015
234  train_mean_loss:  0.0698990003325491  test_loss:  0.6966733
235  train_mean_loss:  0.06988605876210714  test_loss:  0.69674826
236  train_mean_loss:  0.06989126227259226  test_loss:  0.69667244
237  train_mean_loss:  0.06989586203324627  test_loss:  0.69676554
238  train_mean_loss:  0.06989027976171688  test_loss:  0.6967689
239  train_mean_loss:  0.06989744879387737  test_loss:  0.6969554
240  train_mean_loss:  0.06989858375902717  test_loss:  0.6969211
241  train_mean_loss:  0.06989973138135851  test_loss:  0.69682586
242  train_mean_loss:  0.06989507583366565  test_loss:  0.69685286
243  train_mean_loss:  0.06989044457776283  test_loss:  0.6968338
244  train_mean_loss:  0.06989003425329822  test_loss:  0.6968723
245  train_mean_loss:  0.06990194095712648  test_loss:  0.69678575
246  train_mean_loss:  0.06988867852599667  test_loss:  0.69674253
247  train_mean_loss:  0.06988822089048728  test_loss:  0.6967414
248  train_mean_loss:  0.06989672635740513  test_loss:  0.6967527
249  train_mean_loss:  0.0698907210587819  test_loss:  0.69670665
250  train_mean_loss:  0.06988667169237155  test_loss:  0.6966953
251  train_mean_loss:  0.06988921401339818  test_loss:  0.6965733
252  train_mean_loss:  0.06989282024211207  test_loss:  0.69679886
253  train_mean_loss:  0.06989141818089109  test_loss:  0.69648767
254  train_mean_loss:  0.06989920021148752  test_loss:  0.69666934
255  train_mean_loss:  0.06989820845200731  test_loss:  0.6965163
256  train_mean_loss:  0.06988995008417727  test_loss:  0.6964318
257  train_mean_loss:  0.06990342414247322  test_loss:  0.6964051
258  train_mean_loss:  0.06990514556460829  test_loss:  0.69656736
259  train_mean_loss:  0.06990993993226872  test_loss:  0.6963844
260  train_mean_loss:  0.06990956460252501  test_loss:  0.69697046
261  train_mean_loss:  0.06989985438553013  test_loss:  0.6970101
262  train_mean_loss:  0.06990483733837813  test_loss:  0.6965447
263  train_mean_loss:  0.06990482404492895  test_loss:  0.6964702
264  train_mean_loss:  0.06990387064329869  test_loss:  0.696826
265  train_mean_loss:  0.06990461157698055  test_loss:  0.69687843
266  train_mean_loss:  0.06990255168317794  test_loss:  0.6964423
267  train_mean_loss:  0.06990541877339371  test_loss:  0.6968307
268  train_mean_loss:  0.06989946869371322  test_loss:  0.6968944
269  train_mean_loss:  0.0698943132214359  test_loss:  0.6973419
270  train_mean_loss:  0.06989993230559378  test_loss:  0.6975812
271  train_mean_loss:  0.0699103547560546  test_loss:  0.69761854
272  train_mean_loss:  0.06991032453334109  test_loss:  0.6973786
273  train_mean_loss:  0.06990350381227291  test_loss:  0.6965603
274  train_mean_loss:  0.06990305201679162  test_loss:  0.6964676
275  train_mean_loss:  0.06989687965246179  test_loss:  0.6965285
276  train_mean_loss:  0.0698956714710842  test_loss:  0.6969864
277  train_mean_loss:  0.06989733874229725  test_loss:  0.6969325
278  train_mean_loss:  0.06989657624368671  test_loss:  0.6968475
279  train_mean_loss:  0.06989683747700594  test_loss:  0.69717145
280  train_mean_loss:  0.06990357237011251  test_loss:  0.6967391
281  train_mean_loss:  0.06989735160399338  test_loss:  0.69691336
282  train_mean_loss:  0.06990356950690807  test_loss:  0.6963441
283  train_mean_loss:  0.06989681386693125  test_loss:  0.69671875
284  train_mean_loss:  0.0698894384795366  test_loss:  0.6968351
285  train_mean_loss:  0.06989197339258983  test_loss:  0.69679767
286  train_mean_loss:  0.06988783451695502  test_loss:  0.6967783
287  train_mean_loss:  0.06988953728281357  test_loss:  0.696738
288  train_mean_loss:  0.06988997812540168  test_loss:  0.6967076
289  train_mean_loss:  0.06988700023371892  test_loss:  0.69666064
290  train_mean_loss:  0.06989720021773967  test_loss:  0.6966427
291  train_mean_loss:  0.06988974102480558  test_loss:  0.69660527
292  train_mean_loss:  0.06988785358226077  test_loss:  0.69649446
293  train_mean_loss:  0.0698927528659124  test_loss:  0.6965951
294  train_mean_loss:  0.06988902272407307  test_loss:  0.69654906
295  train_mean_loss:  0.06988911166520143  test_loss:  0.6965465
296  train_mean_loss:  0.06989432885544108  test_loss:  0.69656676
297  train_mean_loss:  0.06989327949101444  test_loss:  0.6964296
298  train_mean_loss:  0.0698951403012132  test_loss:  0.69673604
299  train_mean_loss:  0.06988647163164238  test_loss:  0.69671315
test_min_loss:  0.6963441

Process finished with exit code 0
